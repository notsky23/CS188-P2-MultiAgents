# CS188-P2-MultiAgents

Disclaimer: This is my attempt at the CS188 coursework 2 from the University of California, Berkeley.<br>

Project Site: https://inst.eecs.berkeley.edu/~cs188/sp22/projects/.<br><br>

## What is this project about?<br>

This project is a practice with different AI adversarial agents.<br>

In this project, we will create a PacMan AI agent that uses adversarial AI algorithms to calculate which moves would help him win the game or get the highest score it can given various scenarios, or series of goal positions.<br><br>

## Results:<br>

You can read more about this module and deliverables at this site: https://inst.eecs.berkeley.edu/~cs188/sp22/project2/<br>

Here are the results I got for each adversarial agent.<br>

The code is included in this repo.<br><br>

### Q1 - Reflex Agent<br>
![Reflex Agent](https://user-images.githubusercontent.com/98131995/225192276-92bacb79-9fd4-4f10-9ccc-1dc5c64531ac.gif)<br>
![image](https://user-images.githubusercontent.com/98131995/225192418-51290b06-7f41-43ce-8e81-3dfd086197d9.png)<br><br>
![Reflex Agent Q1](https://user-images.githubusercontent.com/98131995/225194965-efab27f5-3534-4971-8145-b9e60d9c6f0b.gif)<br>
![image](https://user-images.githubusercontent.com/98131995/225195091-78ce1b3b-0503-4553-bca5-39a943a0a7dc.png)<br><br>

### Q2 - Minimax<br>
![image](https://user-images.githubusercontent.com/98131995/225205133-2cbf3ee4-e21b-4f8c-876a-3a975871834c.png)<br><br>
![image](https://user-images.githubusercontent.com/98131995/225204969-effee582-3e9c-4c73-b458-5918a893a1df.png)<br><br>
![Minimax Agent](https://user-images.githubusercontent.com/98131995/225198867-25fd61dc-d922-4e76-81b5-ce47f41c5d6a.gif)<br>
![image](https://user-images.githubusercontent.com/98131995/225198926-d44298fd-8d3c-4f75-b57e-8b2dd0df1db1.png)<br><br>
![Minimax Agent Q2](https://user-images.githubusercontent.com/98131995/225200429-f02aeaf6-9731-40b9-8604-5492d46c8ffa.gif)<br>
![image](https://user-images.githubusercontent.com/98131995/225200775-5336017a-a0ed-4a01-a165-1789ea76bdca.png)<br><br>

### Q3 - Alpha-Beta Pruning<br>
![image](https://user-images.githubusercontent.com/98131995/225210795-a45cf7f1-e0e4-4c56-a8f8-e855ce9ad8ba.png)<br><br>
![image](https://user-images.githubusercontent.com/98131995/225210635-0b1a704b-aab2-4234-b568-fdab2f41e00f.png)<br><br>
![AlphaBeta Agent](https://user-images.githubusercontent.com/98131995/225208196-136d44c1-cd62-40fe-8a1c-aa2bee913cf0.gif)<br>
![image](https://user-images.githubusercontent.com/98131995/225208457-a9d333c3-5947-4131-b2f9-6f6cad3a0d93.png)<br><br>
![AlphaBeta Agent Q3](https://user-images.githubusercontent.com/98131995/225209172-94d6f6b1-4b6a-4e3a-b344-535701ac7bd4.gif)<br>
![image](https://user-images.githubusercontent.com/98131995/225209310-b82ea097-2e14-478f-bae5-1227c65e380d.png)<br><br>

### Q4 - Expectimax<br>
![image](https://user-images.githubusercontent.com/98131995/225215031-4f0d9d5c-928b-4c88-80c4-3cf4eb4e5612.png)<br><br>
![image](https://user-images.githubusercontent.com/98131995/225215285-240a6c12-cba5-434f-9e5a-29278fc605f5.png)<br><br>
![Expectimax Agent](https://user-images.githubusercontent.com/98131995/225213467-ea790e53-e637-4801-9c6f-c63ce28141ea.gif)<br>
![image](https://user-images.githubusercontent.com/98131995/225213515-c60bd3e1-7e36-404a-b463-2055fd4781a1.png)<br><br>
![Expectimax Agent Q4](https://user-images.githubusercontent.com/98131995/225214544-1e62bba2-0c28-4ceb-b322-ab3dc2b650e7.gif)<br>
![image](https://user-images.githubusercontent.com/98131995/225214708-eb30bb54-51e2-4e2e-bc8f-1e14d281836c.png)<br><br>

### Q5 - Evaluation Function<br>
![Evaluation Function Q5gif](https://user-images.githubusercontent.com/98131995/225216779-9b183dde-8921-4498-90b5-8e1f4f5bbdea.gif)<br>
![image](https://user-images.githubusercontent.com/98131995/225216921-da0d4bd6-1f97-4179-88ef-d8a7216f3cfe.png)<br><br>
